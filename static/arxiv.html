<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Arxiv
  </title>
  <link href="static/style.css" media="screen" rel="stylesheet" type="text/css"/>
 </head>
</html><h3>Fri, 18 Mar 2016</h3><h3>math.OC</h3><ul><li class="block">
<html>
 <body>
  <input id="item0" name="item" type="checkbox"/>
 </body>
</html> <label for="item0">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05643" style="color:white;">
     <span class="descriptor">
     </span>
     Variance Reduction for Faster Non-Convex Optimization
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     We consider the fundamental problem in non-convex optimization of efficiently
reaching a stationary point. In contrast to the convex case, in the long
history of this basic problem, the only known theoretical results on
first-order non-convex optimization remain to be full gradient descent that
converges in $O(1/\varepsilon)$ iterations for smooth objectives, and
stochastic gradient descent that converges in $O(1/\varepsilon^2)$ iterations
for objectives that are sum of smooth functions.
     <br/>
     We provide the first improvement in this line of research. Our result is
based on the variance reduction trick recently introduced to convex
optimization, as well as a brand new analysis of variance reduction that is
suitable for non-convex optimization. For objectives that are sum of smooth
functions, our first-order minibatch stochastic method converges with an
$O(1/\varepsilon)$ rate, and is faster than full gradient descent by
$\Omega(n^{1/3})$.
     <br/>
     We demonstrate the effectiveness of our methods on empirical risk
minimizations with non-convex loss functions and training neural nets.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item1" name="item" type="checkbox"/>
 </body>
</html> <label for="item1">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05642" style="color:white;">
     <span class="descriptor">
     </span>
     Optimal Black-Box Reductions Between Optimization Objectives
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     The diverse world of machine learning applications has given rise to a
plethora of algorithms and optimization methods, finely tuned to the
smoothness, convexity, and other parameterizations of the objective. In this
paper we attempt to simplify and reduce the complexity of algorithm design for
machine learning by reductions: we develop reductions that take a method
developed for one setting and apply it to the entire spectrum of smoothness and
strong-convexity found in practice.
     <br/>
     We show how these new reductions give rise to faster running times on
training linear classifiers for certain families of loss functions, and that
our reductions are OPTIMAL and cannot be improved in general. We conclude with
experiments showing our reductions successfully transform methods between
domains and achieve the desired performance predicted by theory.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item2" name="item" type="checkbox"/>
 </body>
</html> <label for="item2">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05534" style="color:white;">
     <span class="descriptor">
     </span>
     On Existence of $L^2$-solutions of Coupled Boltzmann Continuous Slowing  Down Transport Equation System
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     The paper considers a coupled system of linear Boltzmann transport equation
(BTE), and its Continuous Slowing Down Approximation (CSDA). This system can be
used to model the relevant transport of particles used e.g. in dose calculation
in radiation therapy. The evolution of charged particles (e.g. electrons and
positrons) are in practice often modelled using the CSDA version of BTE because
of the so-called forward peakedness of scattering events contributing to the
particle fluencies (or particle densities), which causes severe problems for
numerical methods. First, we prove the existence and uniqueness of solutions,
under sufficient criteria and in appropriate $L^2$-based spaces, of a single
(particle) CSDA-equation by using two complementary techniques, the
Lions-Lax-Milgram Theorem (variational approach), and the theory evolution
operators (semigroup approach). The necessary a priori estimates are shown. In
addition, we prove the corresponding results and estimates for the system of
coupled transport equations. The related results are given for the adjoint
problem as well. We also bring up some computational points (e.g. certain
explicit formulas), and we sketch a related inverse problem in a remark at the
end of the paper.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item3" name="item" type="checkbox"/>
 </body>
</html> <label for="item3">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05533" style="color:white;">
     <span class="descriptor">
     </span>
     Compressed sensing of data with a known distribution
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     Compressed sensing is a technique for recovering an unknown sparse signal
from a number of random linear measurements. The number of measurements
required for perfect recovery plays a key role and it exhibits a phase
transition. If the number of measurements exceeds certain level related with
the sparsity of the signal, exact recovery is obtained with high probability.
If the number of measurements is below this level, exact recovery occurs with
very small probability. In this work we are able to reduce this threshold by
incorporating statistical information about the data we wish to recover. Our
algorithm works by minimizing a suitably weighted $\ell_1$-norm, where the
weights are chosen so that the expected statistical dimension of the descent
cones of a weighted cross-polytope is minimized. We also provide Monte Carlo
algorithms for computing intrinsic volumes of these descent cones and
estimating the failure probability of our methods.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item4" name="item" type="checkbox"/>
 </body>
</html> <label for="item4">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05499" style="color:white;">
     <span class="descriptor">
     </span>
     Integral control on nonlinear spaces: two extensions
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     This paper applies the recently developed framework for integral control on
nonlinear spaces to two non-standard cases. First, we show that the property of
perfect target stabilization in presence of actuation bias holds also if this
bias is state dependent. This might not be surprising, but for practical
purposes it provides an easy way to robustly cancel nonlinear dynamics of the
uncontrolled plant. We specifically illustrate this for robust stabilization of
a pendulum at arbitrary angle, a problem posed as non-trivial by some
colleagues. Second, as previous work has been restricted to systems with as
many control inputs as configuration dimensions, we here provide results for
integral control of a non-holonomic system. More precisely, we design robust
steering control of a rigid body under velocity bias.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item5" name="item" type="checkbox"/>
 </body>
</html> <label for="item5">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05498" style="color:white;">
     <span class="descriptor">
     </span>
     Achieving string stability with nonlinear control inspired by a PDE
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     This paper deals with the problem of string stability of unidirectionally
interconnected systems with double-integrator open loop dynamics
(e.g.~acceleration-controlled vehicles). We propose a nonlinear coupling law
derived as an appropriate discrete space approximation of a partial
differential equation (PDE), namely the Korteweg-de Vries equation. We argue
that string instability, an unavoidable shortcoming of linear controllers,
could thus be avoided as the stable propagation behavior of the Korteweg-de
Vries equation carries over to the discretized system. Besides some formal
arguments in this sense, we present simulation results showing that our
nonlinear controller favorably compares to a (failing) linear control and
saturation-based nonlinearity. The results use a notion of string stability
whose nonlinear implications are somewhat adapted.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item6" name="item" type="checkbox"/>
 </body>
</html> <label for="item6">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05445" style="color:white;">
     <span class="descriptor">
     </span>
     Particle-based Gaussian process optimization for input design in  nonlinear dynamical models
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     We propose a novel approach to input design for identification of nonlinear
state space models. The optimal input sequence is obtained by maximizing a
scalar cost function of the Fisher information matrix. Since the Fisher
information matrix is unavailable in closed form, it is estimated using
particle methods. In addition, we make use of Gaussian process optimization to
find the optimal input and to mitigate the problem of a large computational
cost incurred by the particle filter, as the method reduces the number of
functional evaluations. Numerical examples are provided to illustrate the
performance of the resulting algorithm.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item7" name="item" type="checkbox"/>
 </body>
</html> <label for="item7">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05412" style="color:white;">
     <span class="descriptor">
     </span>
     Online semi-parametric learning for inverse dynamics modeling
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     This paper presents a semi-parametric algorithm for online learning of a
robot inverse dynamics model. It combines the strength of the parametric and
non-parametric modeling. The former exploits the rigid body dynamics equation,
while the latter exploits a suitable kernel function. We provide an extensive
comparison with other methods from the literature using real data from the iCub
humanoid robot. In doing so we also compare two different techniques, namely
cross validation and marginal likelihood optimization, for estimating the
hyperparameters of the kernel function.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item8" name="item" type="checkbox"/>
 </body>
</html> <label for="item8">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05398" style="color:white;">
     <span class="descriptor">
     </span>
     A Generic Linear Rate Acceleration of Optimization algorithms via  Relaxation and Inertia
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     Optimization algorithms can often be seen as fixed-points iterations of some
operators. We develop a general analysis of the linear convergence rate of such
iterations and of the methods to accelerate them. Acceleration methods using
previous iterations can be separated in two main types: relaxation (simple
combination of current and previous iterate) and inertia (slightly more
involved modification made popular by Nesterov's acceleration and heavy balls).
These methods have been celebrated for accelerating linearly and sub-linearly
converging algorithms such as gradient methods, proximal gradient (FISTA), or
ADMM (Fast ADMM). In this paper, we build upon generic contraction properties
and affine approximations to i) provide a coherent joint vision of these
methods; ii) analyze the reach and limitations of these modifications; and iii)
propose generic auto-tuned acceleration methods. The performance of these
methods is then evaluated for various optimization algorithms.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item9" name="item" type="checkbox"/>
 </body>
</html> <label for="item9">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05362" style="color:white;">
     <span class="descriptor">
     </span>
     Decompositions and bang-bang properties
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     In this paper, minimal time and minimal norm control problems are studied.
The target sets considered are the origin of state spaces and controls are
point-wisely bounded functions. The system stuided in this paper is assumed to
have no the null controllability or the backward uniqueness property. In this
study, minimal time and minimal norm control problems depend on two parameters,
respectively. Whether these problems hold the bang-bang property also depend on
the parameters. We study the bang-bang property for different parameters for
minimal time and minimal norm control problems, by assuming some kinds of weak
controllability and unique continuation property. These two properties
automatically hold for general time-invariant finitely dimensional controlled
systems.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item10" name="item" type="checkbox"/>
 </body>
</html> <label for="item10">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05305" style="color:white;">
     <span class="descriptor">
     </span>
     Near-Optimal Stochastic Approximation for Online Principal Component  Estimation
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     Principal component analysis (PCA) has been a prominent tool for
high-dimensional data analysis. Online algorithms that estimate the principal
component by processing streaming data are of tremendous practical and
theoretical interests. Despite its rich applications, theoretical convergence
analysis remains largely open. In this paper, we cast online PCA into a
stochastic nonconvex optimization problem, and we analyze the online PCA
algorithm as a stochastic approximation iteration. The stochastic approximation
iteration processes data points incrementally and maintains a running estimate
of the principal component. We prove for the first time a nearly optimal
convergence rate result for the online PCA algorithm. We show that the
finite-sample error closely matches the minimax information lower bound. In
addition, we characterize the convergence process using ordinary and stochastic
differential equation approximations.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item11" name="item" type="checkbox"/>
 </body>
</html> <label for="item11">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05296" style="color:white;">
     <span class="descriptor">
     </span>
     Clustering of Sparse and Approximately Sparse Graphs by Semidefinite  Programming
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     As a model problem for clustering, we consider the densest k-disjoint-clique
problem of partitioning a weighted complete graph into k disjoint subgraphs
such that the sum of the densities of these subgraphs is maximized. We
establish that such subgraphs can be recovered from the solution of a
particular semidefinite relaxation with high probability if the input graph is
sampled from a distribution of clusterable graphs. Specifically, the
semidefinite relaxation is exact if the graph consists of k large disjoint
subgraphs, corresponding to clusters, with weight concentrated within these
subgraphs, plus a moderate number of outliers. Further, we establish that if
noise is weakly obscuring these clusters, i.e, the between-cluster edges are
assigned very small weights, then we can recover significantly smaller
clusters. For example, we show that in approximately sparse graphs, where the
between-cluster weights tend to zero as the size n of the graph tends to
infinity, we can recover clusters of size polylogarithmic in n. Empirical
evidence from numerical simulations is also provided to support these
theoretical phase transitions to perfect recovery of the cluster structure.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item12" name="item" type="checkbox"/>
 </body>
</html> <label for="item12">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05244" style="color:white;">
     <span class="descriptor">
     </span>
     Three-Dimensional Multi-Tethered Satellite Formation with the Elements  Moving Along Lissajous Curves
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     This note presents a novel approach to maintain three-dimensional
multi-tethered satellite formation in space. For a formation consisting of a
main body connected by tethers with several deputy satellites (the so-called
"hub-and-spoke" configuration) we demonstrate that under proper choice of the
system's parameters the deputy satellites can move along Lissajous curves in
the plane normal to the local vertical with all tethers stretched, the total
force due to the tension forces acting on the main satellite is balanced in a
way allowing it to be in relative equilibrium strictly below or strictly above
the system's center of mass. We analyze relations between the system's
essential parameters and obtain conditions under which the proposed motion does
take place. We also study analytically the motion stability for different
configurations and whether the deputy satellites can collide or the tethers can
entangle. Our theoretical findings are corroborated and validated by numerical
experiments.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item13" name="item" type="checkbox"/>
 </body>
</html> <label for="item13">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05285" style="color:white;">
     <span class="descriptor">
     </span>
     Image Labeling by Assignment
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     We introduce a novel geometric approach to the image labeling problem.
Abstracting from specific labeling applications, a general objective function
is defined on a manifold of stochastic matrices, whose elements assign prior
data that are given in any metric space, to observed image measurements. The
corresponding Riemannian gradient flow entails a set of replicator equations,
one for each data point, that are spatially coupled by geometric averaging on
the manifold. Starting from uniform assignments at the barycenter as natural
initialization, the flow terminates at some global maximum, each of which
corresponds to an image labeling that uniquely assigns the prior data. Our
geometric variational approach constitutes a smooth non-convex inner
approximation of the general image labeling problem, implemented with sparse
interior-point numerics in terms of parallel multiplicative updates that
converge efficiently.
    </p>
   </div>
  </li>
 </ul>
</li>
</ul><h3>cs.CV</h3><ul><li class="block">
<html>
 <body>
  <input id="item14" name="item" type="checkbox"/>
 </body>
</html> <label for="item14">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05631" style="color:white;">
     <span class="descriptor">
     </span>
     Generative Image Modeling using Style and Structure Adversarial Networks
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     Current generative frameworks use end-to-end learning and generate images by
sampling from uniform noise distribution. However, these approaches ignore the
most basic principle of image formation: images are product of: (a) Structure:
the underlying 3D model; (b) Style: the texture mapped onto structure. In this
paper, we factorize the image generation process and propose Style and
Structure Generative Adversarial Network (S^2-GAN). Our S^2-GAN has two
components: the Structure-GAN generates a surface normal map; the Style-GAN
takes the surface normal map as input and generates the 2D image. Apart from a
real vs. generated loss function, we use an additional loss with computed
surface normals from generated images. The two GANs are first trained
independently, and then merged together via joint learning. We show our S^2-GAN
model is interpretable, generates more realistic images and can be used to
learn unsupervised RGBD representations.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item15" name="item" type="checkbox"/>
 </body>
</html> <label for="item15">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05600" style="color:white;">
     <span class="descriptor">
     </span>
     "What happens if..." Learning to Predict the Effect of Forces in Images
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     What happens if one pushes a cup sitting on a table toward the edge of the
table? How about pushing a desk against a wall? In this paper, we study the
problem of understanding the movements of objects as a result of applying
external forces to them. For a given force vector applied to a specific
location in an image, our goal is to predict long-term sequential movements
caused by that force. Doing so entails reasoning about scene geometry, objects,
their attributes, and the physical rules that govern the movements of objects.
We design a deep neural network model that learns long-term sequential
dependencies of object movements while taking into account the geometry and
appearance of the scene by combining Convolutional and Recurrent Neural
Networks. Training our model requires a large-scale dataset of object movements
caused by external forces. To build a dataset of forces in scenes, we
reconstructed all images in SUN RGB-D dataset in a physics simulator to
estimate the physical movements of objects caused by external forces applied to
them. Our Forces in Scenes (ForScene) dataset contains 10,335 images in which a
variety of external forces are applied to different types of objects resulting
in more than 65,000 object movements represented in 3D. Our experimental
evaluations show that the challenging task of predicting long-term movements of
objects as their reaction to external forces is possible from a single image.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item16" name="item" type="checkbox"/>
 </body>
</html> <label for="item16">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05474" style="color:white;">
     <span class="descriptor">
     </span>
     Neural Aggregation Network for Video Face Recognition
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     In this paper, we present a Neural Aggregation Network (NAN) for video face
recognition. The network takes a face video or face image set of a person with
variable number of face frames as its input, and produces a compact and
fixed-dimension visual representation of that person. The whole network is
composed of two modules. The feature embedding module is a CNN which maps each
face frame into a feature representation. The neural aggregation module is
composed of two content based attention blocks which is driven by a memory
storing all the features extracted from the face video through the feature
embedding module. The output of the first attention block adapts the second,
whose output is adopted as the aggregated representation of the video faces.
Due to the attention mechanism, this representation is invariant to the order
of the face frames. The experiments show that the proposed NAN consistently
outperforms hand-crafted aggregations such as average pooling, and achieves
state-of-the-art accuracy on three video face recognition datasets: the YouTube
Face, IJB-A and Celebrity-1000 datasets.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item17" name="item" type="checkbox"/>
 </body>
</html> <label for="item17">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05414" style="color:white;">
     <span class="descriptor">
     </span>
     Variable-Length Hashing
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     Hashing has emerged as a popular technique for large-scale similarity search.
Most learning-based hashing methods generate compact yet correlated hash codes.
However, this redundancy is storage-inefficient. Hence we propose a lossless
variable-length hashing (VLH) method that is both storage- and
search-efficient. Storage efficiency is achieved by converting the fixed-length
hash code into a variable-length code. Search efficiency is obtained by using a
multiple hash table structure. With VLH, we are able to deliberately add
redundancy into hash codes to improve retrieval performance with little
sacrifice in storage efficiency or search complexity. In particular, we propose
a block K-means hashing (B-KMH) method to obtain significantly improved
retrieval performance with no increase in storage and marginal increase in
computational cost.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item18" name="item" type="checkbox"/>
 </body>
</html> <label for="item18">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05335" style="color:white;">
     <span class="descriptor">
     </span>
     Saliency Detection with Spaces of Background-based Distribution
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     In this letter, an effective image saliency detection method is proposed by
constructing some novel spaces to model the background and redefine the
distance of the salient patches away from the background. Concretely, given the
backgroundness prior, eigendecomposition is utilized to create four spaces of
background-based distribution (SBD) to model the background, in which a more
appropriate metric (Mahalanobis distance) is quoted to delicately measure the
saliency of every image patch away from the background. After that, a coarse
saliency map is obtained by integrating the four adjusted Mahalanobis distance
maps, each of which is formed by the distances between all the patches and
background in the corresponding SBD. To be more discriminative, the coarse
saliency map is further enhanced into the posterior probability map within
Bayesian perspective. Finally, the final saliency map is generated by properly
refining the posterior probability map with geodesic distance. Experimental
results on two usual datasets show that the proposed method is effective
compared with the state-of-the-art algorithms.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item19" name="item" type="checkbox"/>
 </body>
</html> <label for="item19">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05285" style="color:white;">
     <span class="descriptor">
     </span>
     Image Labeling by Assignment
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     We introduce a novel geometric approach to the image labeling problem.
Abstracting from specific labeling applications, a general objective function
is defined on a manifold of stochastic matrices, whose elements assign prior
data that are given in any metric space, to observed image measurements. The
corresponding Riemannian gradient flow entails a set of replicator equations,
one for each data point, that are spatially coupled by geometric averaging on
the manifold. Starting from uniform assignments at the barycenter as natural
initialization, the flow terminates at some global maximum, each of which
corresponds to an image labeling that uniquely assigns the prior data. Our
geometric variational approach constitutes a smooth non-convex inner
approximation of the general image labeling problem, implemented with sparse
interior-point numerics in terms of parallel multiplicative updates that
converge efficiently.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item20" name="item" type="checkbox"/>
 </body>
</html> <label for="item20">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05279" style="color:white;">
     <span class="descriptor">
     </span>
     XNOR-Net: ImageNet Classification Using Binary Convolutional Neural  Networks
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     We propose two efficient approximations to standard convolutional neural
networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks,
the filters are approximated with binary values resulting in 32x memory saving.
In XNOR-Networks, both the filters and the input to convolutional layers are
binary. XNOR-Networks approximate convolutions using primarily binary
operations. This results in 58x faster convolutional operations and 32x memory
savings. XNOR-Nets offer the possibility of running state-of-the-art networks
on CPUs (rather than GPUs) in real-time. Our binary networks are simple,
accurate, efficient, and work on challenging visual tasks. We evaluate our
approach on the ImageNet classification task. The classification accuracy with
a Binary-Weight-Network version of AlexNet is only 2.9% less than the
full-precision AlexNet (in top-1 measure). We compare our method with recent
network binarization methods, BinaryConnect and BinaryNets, and outperform
these methods by large margins on ImageNet, more than 16% in top-1 accuracy.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item21" name="item" type="checkbox"/>
 </body>
</html> <label for="item21">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05522" style="color:white;">
     <span class="descriptor">
     </span>
     Tracking multiple moving objects in images using Markov Chain Monte  Carlo
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     A new Bayesian state and parameter learning algorithm for multiple target
tracking (MTT) models with image observations is proposed. Specifically, a
Markov chain Monte Carlo algorithm is designed to sample from the posterior
distribution of the unknown number of targets, their birth and death times,
states and model parameters, which constitutes the complete solution to the
tracking problem. The conventional approach is to pre-process the images to
extract point observations and then perform tracking. We model the image
generation process directly to avoid potential loss of information when
extracting point observations. Numerical examples show that our algorithm has
improved tracking performance over commonly used techniques, for both synthetic
examples and real florescent microscopy data, especially in the case of dim
targets with overlapping illuminated regions.
    </p>
   </div>
  </li>
 </ul>
</li>
<li class="block">
<html>
 <body>
  <input id="item22" name="item" type="checkbox"/>
 </body>
</html> <label for="item22">
<html>
 <body>
  <i aria-hidden="true">
  </i>
 </body>
</html>  <h2>
   <div>
    <a href="http://arxiv.org/pdf/1603.05310" style="color:white;">
     <span class="descriptor">
     </span>
     Persistent Homology of Attractors For Action Recognition
    </a>
   </div>
  </h2>
 </label>
 <ul class="options">
  <li>
   <div>
    <p>
     <span class="descriptor">
      Abstract:
     </span>
     In this paper, we propose a novel framework for dynamical analysis of human
actions from 3D motion capture data using topological data analysis. We model
human actions using the topological features of the attractor of the dynamical
system. We reconstruct the phase-space of time series corresponding to actions
using time-delay embedding, and compute the persistent homology of the
phase-space reconstruction. In order to better represent the topological
properties of the phase-space, we incorporate the temporal adjacency
information when computing the homology groups. The persistence of these
homology groups encoded using persistence diagrams are used as features for the
actions. Our experiments with action recognition using these features
demonstrate that the proposed approach outperforms other baseline methods.
    </p>
   </div>
  </li>
 </ul>
</li>
</ul>